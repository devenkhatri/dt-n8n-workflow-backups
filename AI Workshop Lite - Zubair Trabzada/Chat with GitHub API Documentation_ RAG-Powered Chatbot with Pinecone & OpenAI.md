# Workflow Analysis for Chat with GitHub OpenAPI Specification using RAG (Pinecone and OpenAI)

## Description
This workflow creates an API documentation chatbot for the GitHub API using Retrieval Augmented Generation (RAG). It leverages OpenAI for generating embeddings and responses, and Pinecone as a vector database. The workflow indexes the GitHub OpenAPI specifications, allowing users to chat and receive relevant information about the API based on the indexed data.

## Input Details
The workflow is triggered either manually to index the OpenAPI specification, or by a chat message received from a user to answer questions.

## Process Summary
First, the workflow fetches the GitHub OpenAPI specification via an HTTP request. The specification is then processed by a Default Data Loader and split into chunks using a Recursive Character Text Splitter. Embeddings for these chunks are generated using OpenAI and stored in a Pinecone vector database. For chat interactions, a received chat message triggers an AI Agent. This agent utilizes an OpenAI Chat Model, a Window Buffer Memory for conversation context, and a Vector Store Tool that queries the Pinecone database using embeddings generated by another OpenAI embedding model to retrieve relevant information. Finally, the AI Agent generates a response.

## Output Details
The workflow produces intelligent chat responses to user queries, providing information about the GitHub API based on its OpenAPI specifications.
